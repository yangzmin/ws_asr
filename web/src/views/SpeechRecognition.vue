<template>
  <div class="speech-recognition">
    <h1>ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ« + AIèŠå¤©</h1>
    
    <div class="control-panel">
      <div class="device-selector">
        <label for="audioDevice">é€‰æ‹©éº¦å…‹é£ï¼š</label>
        <select id="audioDevice" v-model="selectedDevice" @change="updateAudioDevice">
          <option v-for="device in audioDevices" :key="device.deviceId" :value="device.deviceId">
            {{ device.label }}
          </option>
        </select>
      </div>
      
      <div class="recording-controls">
        <button @click="startRecording" :disabled="isRecording" class="start-btn">
          å¼€å§‹å½•éŸ³
        </button>
        <button @click="stopRecording" :disabled="!isRecording" class="stop-btn">
          åœæ­¢å½•éŸ³
        </button>
      </div>
      
      <div class="status-indicators">
        <div class="status-item">
          <span class="status-label">WebSocket:</span>
          <span :class="wsConnected ? 'status-connected' : 'status-disconnected'">
            {{ wsConnected ? 'å·²è¿æ¥' : 'æœªè¿æ¥' }}
          </span>
        </div>
        <div class="status-item">
          <span class="status-label">å½•éŸ³çŠ¶æ€:</span>
          <span :class="isRecording ? 'status-recording' : 'status-idle'">
            {{ isRecording ? 'å½•éŸ³ä¸­' : 'ç©ºé—²' }}
          </span>
        </div>
      </div>
    </div>

    <div class="results-section">
      <div class="recognition-results">
        <h3>è¯­éŸ³è¯†åˆ«ç»“æœ:</h3>
        <div class="text-box">
          <div class="interim-text">{{ recognitionText }}</div>
          <div class="final-text">{{ fullText }}</div>
        </div>
      </div>

      <div class="chat-results">
        <h3>AIèŠå¤©å›å¤:</h3>
        <div class="chat-box">
          <div v-if="chatLoading" class="chat-loading">æ­£åœ¨æ€è€ƒä¸­...</div>
          <div class="chat-content">{{ chatResponse }}</div>
          <div v-if="chatError" class="chat-error">{{ chatError }}</div>
        </div>
        
        <!-- TTSéŸ³é¢‘æ’­æ”¾æ§åˆ¶ -->
        <div class="tts-controls" v-if="chatResponse">
          <div class="tts-status">
            <span class="status-label">è¯­éŸ³åˆæˆ:</span>
            <span :class="ttsStatus === 'playing' ? 'status-playing' : ttsStatus === 'loading' ? 'status-loading' : 'status-idle'">
              {{ ttsStatusText }}
            </span>
          </div>
          <div class="audio-controls">
            <button @click="toggleAudio" :disabled="!hasAudio" class="audio-btn">
              {{ isAudioPlaying ? 'æš‚åœæ’­æ”¾' : 'æ’­æ”¾è¯­éŸ³' }}
            </button>
            <button @click="stopAudio" :disabled="!hasAudio" class="audio-btn stop-audio">
              åœæ­¢æ’­æ”¾
            </button>
          </div>
        </div>
      </div>
    </div>

    <div class="audio-visualization">
      <canvas ref="canvas" width="800" height="200"></canvas>
    </div>
  </div>
</template>

<script setup>
import { ref, computed, onMounted, onUnmounted } from 'vue'
import { message } from 'ant-design-vue'
import { createAudioProcessor, audioDataToWavBase64 } from '@/utils/audioUtils'

// å“åº”å¼æ•°æ®
const selectedDevice = ref('')
const audioDevices = ref([])
const isRecording = ref(false)
const wsConnected = ref(false)
const recognitionText = ref('')
const fullText = ref('')
const chatResponse = ref('')
const chatLoading = ref(false)
const chatError = ref('')

// TTSç›¸å…³çŠ¶æ€
const ttsStatus = ref('idle') // idle, loading, playing, paused
const isAudioPlaying = ref(false)
const hasAudio = ref(false)
const audioChunks = ref([])
const currentAudio = ref(null)

// refs
const canvas = ref(null)
const wsRef = ref(null)
const processorRef = ref(null)
const wsCloseTimerRef = ref(null)

// è®¡ç®—å±æ€§
const ttsStatusText = computed(() => {
  switch (ttsStatus.value) {
    case 'loading': return 'åˆæˆä¸­...'
    case 'playing': return 'æ’­æ”¾ä¸­'
    case 'paused': return 'å·²æš‚åœ'
    default: return 'å°±ç»ª'
  }
})

onMounted(async () => {
  await getAudioDevices()
})

onUnmounted(() => {
  if (wsRef.value) {
    wsRef.value.close()
  }
  if (wsCloseTimerRef.value) {
    clearTimeout(wsCloseTimerRef.value)
  }
  stopRecording()
})

const getAudioDevices = async () => {
  try {
    const devices = await navigator.mediaDevices.enumerateDevices()
    const audioInputs = devices
      .filter(device => device.kind === 'audioinput')
      .map(device => ({
        deviceId: device.deviceId,
        label: device.label || `éº¦å…‹é£ ${device.deviceId.slice(0, 8)}`
      }))
    audioDevices.value = audioInputs
    if (audioInputs.length > 0) {
      selectedDevice.value = audioInputs[0].deviceId
    }
  } catch (error) {
    console.error('è·å–éŸ³é¢‘è®¾å¤‡å¤±è´¥:', error)
    message.error('æ— æ³•è·å–éŸ³é¢‘è®¾å¤‡')
  }
}

// WebSocketè¿æ¥
const connectWebSocket = () => {
  const ws = new WebSocket('ws://localhost:8080/api/ws')
  
  ws.onopen = () => {
    console.log('WebSocketè¿æ¥å·²å»ºç«‹')
    wsConnected.value = true
    
    // å‘é€å¼€å§‹è¯†åˆ«æ¶ˆæ¯
    const startMessage = {
      type: 'start_recognition',
      audio_config: {
        sample_rate: 16000,
        channels: 1,
        format: 'pcm'
      }
    }
    ws.send(JSON.stringify(startMessage))
  }
  
  ws.onmessage = (event) => {
    try {
      const result = JSON.parse(event.data)
      
      // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ
      if (result.type === 'recognition_result') {
        if (result.is_final) {
          fullText.value += result.text + ' '
          recognitionText.value = ''
        } else {
          recognitionText.value = result.text
        }
      }
      
      // å¤„ç†èŠå¤©æµå¼å›å¤
      else if (result.type === 'chat_chunk') {
        chatLoading.value = false
        chatError.value = ''
        chatResponse.value += result.content || ''
      }
      
      // å¤„ç†èŠå¤©å®Œæˆ
      else if (result.type === 'chat_done') {
        chatLoading.value = false
        console.log('AIèŠå¤©å›å¤å®Œæˆ')
      }
      
      // å¤„ç†èŠå¤©é”™è¯¯
      else if (result.type === 'chat_error') {
        chatLoading.value = false
        chatError.value = result.error || 'èŠå¤©å‡ºç°é”™è¯¯'
      }
      
      // å¤„ç†TTSå¼€å§‹
      else if (result.type === 'tts_start') {
        console.log('TTSå¼€å§‹åˆæˆ')
        ttsStatus.value = 'loading'
        audioChunks.value = []
        hasAudio.value = false
      }
      
      // å¤„ç†TTSéŸ³é¢‘æ•°æ®
      else if (result.type === 'tts_audio') {
        if (result.audio_data) {
          audioChunks.value.push(result.audio_data)
          hasAudio.value = true
        }
      }
      
      // å¤„ç†TTSå®Œæˆ
      else if (result.type === 'tts_done') {
        console.log('TTSåˆæˆå®Œæˆ')
        ttsStatus.value = 'idle'
        if (audioChunks.value.length > 0) {
          createAudioFromChunks()
        }
      }
      
      // å¤„ç†TTSé”™è¯¯
      else if (result.type === 'tts_error') {
        console.error('TTSé”™è¯¯:', result.error)
        ttsStatus.value = 'idle'
        message.error('è¯­éŸ³åˆæˆå¤±è´¥: ' + (result.error || 'æœªçŸ¥é”™è¯¯'))
      }
      
    } catch (error) {
      console.error('è§£ææ¶ˆæ¯å¤±è´¥:', error)
    }
  }
  
  ws.onclose = () => {
    console.log('WebSocketè¿æ¥å·²å…³é—­')
    wsConnected.value = false
  }
  
  ws.onerror = (error) => {
    console.error('WebSocketé”™è¯¯:', error)
    message.error('WebSocketè¿æ¥å¤±è´¥')
    wsConnected.value = false
  }
  
  wsRef.value = ws
}

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      audio: {
        deviceId: selectedDevice.value ? { exact: selectedDevice.value } : undefined,
        sampleRate: 16000,
        channelCount: 1,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })

    // é‡ç½®èŠå¤©çŠ¶æ€
    chatResponse.value = ''
    chatError.value = ''
    chatLoading.value = false
    
    // é‡ç½®TTSçŠ¶æ€
    ttsStatus.value = 'idle'
    isAudioPlaying.value = false
    hasAudio.value = false
    audioChunks.value = []
    if (currentAudio.value) {
      currentAudio.value.pause()
      currentAudio.value = null
    }

    // è¿æ¥WebSocket
    connectWebSocket()

    isRecording.value = true
    
    // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨ï¼ˆå†…éƒ¨å·²å›ºå®šé‡‡æ ·ç‡ä¸º16kï¼‰
    const processor = createAudioProcessor(stream, (audioData) => {
      // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨ï¼ˆå‘é€PCMï¼Œæ— WAVå¤´ï¼‰
      if (wsRef.value && wsRef.value.readyState === WebSocket.OPEN) {
        const messageObj = {
          type: 'audio_data',
          data: audioDataToWavBase64(audioData, 16000, 1, false),
          sequence: Date.now(),
          is_final: false
        }
        wsRef.value.send(JSON.stringify(messageObj))
        
        // å¯è§†åŒ–éŸ³é¢‘
        visualizeAudio(audioData)
      }
    })
    
    processorRef.value = processor
    
    message.success('å½•éŸ³å·²å¼€å§‹')
  } catch (error) {
    console.error('å¼€å§‹å½•éŸ³å¤±è´¥:', error)
    message.error('æ— æ³•è®¿é—®éº¦å…‹é£')
  }
}

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  if (isRecording.value) {
    isRecording.value = false
    
    // å‘é€æœ€åä¸€ä¸ªéŸ³é¢‘åŒ…
    if (wsRef.value && wsRef.value.readyState === WebSocket.OPEN) {
      const finalMessage = {
        type: 'audio_data',
        data: '',
        sequence: Date.now(),
        is_final: true
      }
      wsRef.value.send(JSON.stringify(finalMessage))
      
      // å‘é€åœæ­¢è¯†åˆ«æ¶ˆæ¯
      const stopMessage = {
        type: 'stop_recognition'
      }
      wsRef.value.send(JSON.stringify(stopMessage))
      
      // è®¾ç½®èŠå¤©åŠ è½½çŠ¶æ€
      chatLoading.value = true
    }
    
    // åœæ­¢éŸ³é¢‘å¤„ç†
    if (processorRef.value) {
      processorRef.value.stop()
      processorRef.value = null
    }
    
    message.success('å½•éŸ³å·²åœæ­¢')
  }
}

// æ›´æ–°éŸ³é¢‘è®¾å¤‡
const updateAudioDevice = () => {
  if (isRecording.value) {
    message.warning('è¯·å…ˆåœæ­¢å½•éŸ³å†åˆ‡æ¢è®¾å¤‡')
    return
  }
  console.log('åˆ‡æ¢éŸ³é¢‘è®¾å¤‡:', selectedDevice.value)
}

// éŸ³é¢‘å¯è§†åŒ–
const visualizeAudio = (audioData) => {
  if (!canvas.value) return
  
  const ctx = canvas.value.getContext('2d')
  const width = canvas.value.width
  const height = canvas.value.height
  
  ctx.clearRect(0, 0, width, height)
  ctx.fillStyle = '#1890ff'
  
  const barWidth = width / audioData.length
  for (let i = 0; i < audioData.length; i++) {
    const barHeight = (audioData[i] + 1) * height / 4
    ctx.fillRect(i * barWidth, height / 2 - barHeight / 2, barWidth - 1, barHeight)
  }
}

// TTSéŸ³é¢‘å¤„ç†å‡½æ•°
const createAudioFromChunks = () => {
  try {
    // å°†æ‰€æœ‰base64éŸ³é¢‘å—åˆå¹¶
    const combinedBase64 = audioChunks.value.join('')
    
    // è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ•°æ®
    const binaryString = atob(combinedBase64)
    const bytes = new Uint8Array(binaryString.length)
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i)
    }
    
    // åˆ›å»ºéŸ³é¢‘blob
    const audioBlob = new Blob([bytes], { type: 'audio/wav' })
    const audioUrl = URL.createObjectURL(audioBlob)
    
    // åˆ›å»ºéŸ³é¢‘å…ƒç´ 
    const audio = new Audio(audioUrl)
    
    // è®¾ç½®éŸ³é¢‘äº‹ä»¶ç›‘å¬å™¨
    audio.onplay = () => {
      ttsStatus.value = 'playing'
      isAudioPlaying.value = true
    }
    
    audio.onpause = () => {
      ttsStatus.value = 'paused'
      isAudioPlaying.value = false
    }
    
    audio.onended = () => {
      ttsStatus.value = 'idle'
      isAudioPlaying.value = false
      URL.revokeObjectURL(audioUrl)
    }
    
    audio.onerror = (error) => {
      console.error('éŸ³é¢‘æ’­æ”¾é”™è¯¯:', error)
      ttsStatus.value = 'idle'
      isAudioPlaying.value = false
      message.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥')
      URL.revokeObjectURL(audioUrl)
    }
    
    currentAudio.value = audio
    hasAudio.value = true
    
    // è‡ªåŠ¨å¼€å§‹æ’­æ”¾
    audio.play().catch(error => {
      console.error('è‡ªåŠ¨æ’­æ”¾å¤±è´¥:', error)
      message.error('éŸ³é¢‘è‡ªåŠ¨æ’­æ”¾å¤±è´¥')
      ttsStatus.value = 'idle'
    })
    
    console.log('éŸ³é¢‘åˆ›å»ºæˆåŠŸï¼Œè‡ªåŠ¨æ’­æ”¾ä¸­')
  } catch (error) {
    console.error('åˆ›å»ºéŸ³é¢‘å¤±è´¥:', error)
    message.error('éŸ³é¢‘å¤„ç†å¤±è´¥')
  }
}

// åˆ‡æ¢éŸ³é¢‘æ’­æ”¾/æš‚åœ
const toggleAudio = () => {
  if (!currentAudio.value) return
  
  if (isAudioPlaying.value) {
    currentAudio.value.pause()
  } else {
    currentAudio.value.play().catch(error => {
      console.error('æ’­æ”¾å¤±è´¥:', error)
      message.error('éŸ³é¢‘æ’­æ”¾å¤±è´¥')
    })
  }
}

// åœæ­¢éŸ³é¢‘æ’­æ”¾
const stopAudio = () => {
  if (!currentAudio.value) return
  
  currentAudio.value.pause()
  currentAudio.value.currentTime = 0
  ttsStatus.value = 'idle'
  isAudioPlaying.value = false
}
</script>

<style scoped>
.speech-recognition {
  max-width: 1200px;
  margin: 0 auto;
  padding: 20px;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
}

h1 {
  text-align: center;
  color: #1890ff;
  margin-bottom: 30px;
}

.control-panel {
  background: #f5f5f5;
  padding: 20px;
  border-radius: 8px;
  margin-bottom: 20px;
}

.device-selector {
  margin-bottom: 20px;
}

.device-selector label {
  display: inline-block;
  width: 100px;
  font-weight: bold;
}

.device-selector select {
  padding: 8px 12px;
  border: 1px solid #d9d9d9;
  border-radius: 4px;
  width: 300px;
}

.recording-controls {
  margin-bottom: 20px;
}

.start-btn, .stop-btn {
  padding: 10px 20px;
  margin-right: 10px;
  border: none;
  border-radius: 4px;
  font-size: 16px;
  cursor: pointer;
  transition: background-color 0.3s;
}

.start-btn {
  background-color: #52c41a;
  color: white;
}

.start-btn:hover:not(:disabled) {
  background-color: #73d13d;
}

.stop-btn {
  background-color: #ff4d4f;
  color: white;
}

.stop-btn:hover:not(:disabled) {
  background-color: #ff7875;
}

.start-btn:disabled, .stop-btn:disabled {
  background-color: #d9d9d9;
  cursor: not-allowed;
}

.status-indicators {
  display: flex;
  gap: 20px;
}

.status-item {
  display: flex;
  align-items: center;
}

.status-label {
  font-weight: bold;
  margin-right: 8px;
}

.status-connected {
  color: #52c41a;
}

.status-disconnected {
  color: #ff4d4f;
}

.status-recording {
  color: #ff7875;
  animation: pulse 1s infinite;
}

.status-idle {
  color: #8c8c8c;
}

@keyframes pulse {
  0% { opacity: 1; }
  50% { opacity: 0.5; }
  100% { opacity: 1; }
}

.results-section {
  display: grid;
  grid-template-columns: 1fr 1fr;
  grid-gap: 20px;
  margin-bottom: 20px;
}

.recognition-results, .chat-results {
  background: white;
  border: 1px solid #d9d9d9;
  border-radius: 8px;
  padding: 20px;
}

.recognition-results h3, .chat-results h3 {
  margin-top: 0;
  color: #1890ff;
}

.text-box, .chat-box {
  min-height: 200px;
  max-height: 400px;
  overflow-y: auto;
  padding: 15px;
  background: #fafafa;
  border-radius: 4px;
  border: 1px solid #e8e8e8;
}

.interim-text {
  color: #8c8c8c;
  font-style: italic;
  margin-bottom: 10px;
}

.final-text {
  color: #262626;
  line-height: 1.6;
}

.chat-content {
  color: #262626;
  line-height: 1.6;
  white-space: pre-wrap;
}

.chat-loading {
  color: #1890ff;
  font-style: italic;
  animation: pulse 1s infinite;
}

.chat-error {
  color: #ff4d4f;
  font-weight: bold;
  margin-top: 10px;
}

.tts-controls {
  margin-top: 15px;
  padding-top: 15px;
  border-top: 1px solid #e8e8e8;
}

.tts-status {
  margin-bottom: 10px;
}

.status-playing {
  color: #52c41a;
  animation: pulse 1s infinite;
}

.status-loading {
  color: #1890ff;
  animation: pulse 1s infinite;
}

.audio-controls {
  display: flex;
  gap: 10px;
}

.audio-btn {
  padding: 8px 16px;
  border: 1px solid #d9d9d9;
  border-radius: 4px;
  background: white;
  color: #262626;
  cursor: pointer;
  transition: all 0.3s;
}

.audio-btn:hover:not(:disabled) {
  border-color: #1890ff;
  color: #1890ff;
}

.audio-btn:disabled {
  background: #f5f5f5;
  color: #bfbfbf;
  cursor: not-allowed;
}

.stop-audio {
  border-color: #ff4d4f;
  color: #ff4d4f;
}

.stop-audio:hover:not(:disabled) {
  background: #ff4d4f;
  color: white;
}

.audio-visualization {
  background: white;
  border: 1px solid #d9d9d9;
  border-radius: 8px;
  padding: 20px;
  text-align: center;
}

canvas {
  border: 1px solid #e8e8e8;
  border-radius: 4px;
  background: #fafafa;
}

@media (max-width: 768px) {
  .results-section {
    grid-template-columns: 1fr;
  }
  
  .device-selector select {
    width: 100%;
  }
  
  canvas {
    width: 100%;
    height: 150px;
  }
}
</style>